{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendendo OpenCV\n",
    "\n",
    "## Leitura de imagem\n",
    "\n",
    "anotações do processo de aprendizado de uso da biblioteca OpenCV em Python a partir das notas do site [LearnOpenCV](https://learnopencv.com/getting-started-with-opencv/)\n",
    "\n",
    "O método `cv2.imread` lê uma imagem em qualquer formato de imagem e retorna como um array de matrizes, cada matriz possui um valor de cor *BGR* (Blue - Green - Red). Ele pode receber como segundo argumento uma flag que diz como a imagem deve ser representada:\n",
    "\n",
    "* cv2.IMREAD_UNCHANGED / -1 = ...\n",
    "* cv2.IMREAD_GRAYSCALE / 0 = lê a imagem em escala de cinza\n",
    "* cv2.IMREAD_COLOR / 1 = lê a imagem como está\n",
    "\n",
    "O método `cv2.imshow` pega o array e exibe a imagem\n",
    "\n",
    "Os métodos `cv2.waitKey()` e `cv2.destroyAllWindows()` são utilizados para parar a exibição da imagem, ao apertart qualquer tecla (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/mateusglg/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 67 142 228]\n",
      "  [ 67 142 228]\n",
      "  [ 68 143 229]\n",
      "  ...\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]]\n",
      "\n",
      " [[ 68 143 229]\n",
      "  [ 68 143 229]\n",
      "  [ 69 144 230]\n",
      "  ...\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]]\n",
      "\n",
      " [[ 69 145 228]\n",
      "  [ 70 146 229]\n",
      "  [ 70 146 229]\n",
      "  ...\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]\n",
      "  [ 46 108 179]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 81 144 224]\n",
      "  [ 81 144 224]\n",
      "  [ 80 143 223]\n",
      "  ...\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]]\n",
      "\n",
      " [[ 84 147 227]\n",
      "  [ 81 144 224]\n",
      "  [ 78 141 221]\n",
      "  ...\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]]\n",
      "\n",
      " [[ 84 147 227]\n",
      "  [ 81 144 224]\n",
      "  [ 78 141 221]\n",
      "  ...\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]\n",
      "  [ 18  62 125]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./test.jpg')\n",
    "img_grayscale = cv2.imread('./test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_unchanged = cv2.imread('./test.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "cv2.imshow('imagem', img)\n",
    "cv2.imshow('imagem grayscale', img_grayscale)\n",
    "cv2.imshow('imagem nao alterada', img_unchanged)\n",
    "\n",
    "print(img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redimensionamento de imagens\n",
    "\n",
    "A propriedade `img.shape` returna uma tripla que possui os valores de largura, altura e canais.\n",
    "\n",
    "Para mudar o tamanho da imagem, é utilizado o método `cv2.resize`, que recebe a imagem, a tupla de tamanho e uma flag de interpolação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original heigth and width:  353 x 1024\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('test2.jpg')\n",
    "\n",
    "h,w,c = image.shape\n",
    "print(\"Original heigth and width: \", h, \"x\", w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_width = 300\n",
    "down_height = 200\n",
    "down_points = (down_width, down_height)\n",
    "resized_down = cv2.resize(image, down_points, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_width = 600\n",
    "up_height = 400\n",
    "up_points = (up_width, up_height)\n",
    "\n",
    "resized_up = cv2.resize(image, up_points, interpolation = cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Resized Down by defining height and width', resized_down)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Resized Up image by defining height and width', resized_up)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível redimensionar utilizando um fator de escalamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Up the image 1.2 times by specifying both scaling factors\n",
    "scale_up_x = 1.2\n",
    "scale_up_y = 1.2\n",
    "# Scaling Down the image 0.6 times specifying a single scale factor.\n",
    "scale_down = 0.6\n",
    " \n",
    "scaled_f_down = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_LINEAR)\n",
    "scaled_f_up = cv2.resize(image, None, fx= scale_up_x, fy= scale_up_y, interpolation= cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Resized Down by defining scaling factor', scaled_f_down)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Resized Up image by defining scaling factor', scaled_f_up)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de interpolação\n",
    "\n",
    "Os métodos de **Interpolação** disponíveis no OpenCV são:\n",
    "\n",
    "* INTER_AREA = usa a relação de pixels da área para reamostragem. É útil para reduzir o tamanho de uma imagem.\n",
    "* INTER_CUBIC = usa a interpolação bicúbica para redimencionar a imagem. Esse método age nos pixels em uma vizinhança 4x4. Com isso, ele tira média dos pesos dos 16 pixels para criar um novo pixel interpolado\n",
    "* INTER_LINEAR = Funciona como o CUBIC, mas usa vizinhanças menores de 2x2.\n",
    "* INTER_NEAREST = usa o conceito de vizinhos próximos para a interpolação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_inter_nearest = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_NEAREST)\n",
    "res_inter_linear = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_LINEAR)\n",
    "res_inter_area = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate images in horizontal axis for comparison\n",
    "vertical= np.concatenate((res_inter_nearest, res_inter_linear, res_inter_area), axis = 0)\n",
    "# Display the image Press any key to continue\n",
    "cv2.imshow('Inter Nearest :: Inter Linear :: Inter Area', vertical)\n",
    "\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping / recorte de imagem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para recortar uma imagem, é só utilizar as características de matriz dela e utilizar os slices de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread('test.jpg')\n",
    "cv2.imshow(\"original\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Cropping an image\n",
    "cropped_image = img[80:280, 150:330]\n",
    " \n",
    "# Display cropped image\n",
    "cv2.imshow(\"cropped\", cropped_image)\n",
    " \n",
    "# Save the cropped image\n",
    "cv2.imwrite(\"Cropped Image.jpg\", cropped_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível utilizar a função de recorte para recortar a imagem em pequenas subunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test.jpg\")\n",
    "image_copy = img.copy() \n",
    "imgheight = img.shape[0]\n",
    "imgwidth = img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 76\n",
    "N = 104\n",
    "x1 = 0\n",
    "y1 = 0\n",
    " \n",
    "for y in range(0, imgheight, M):\n",
    "    for x in range(0, imgwidth, N):\n",
    "        if (imgheight - y) < M or (imgwidth - x) < N:\n",
    "            break\n",
    "             \n",
    "        y1 = y + M\n",
    "        x1 = x + N\n",
    " \n",
    "        # check whether the patch width or height exceeds the image width or height\n",
    "        if x1 >= imgwidth and y1 >= imgheight:\n",
    "            x1 = imgwidth - 1\n",
    "            y1 = imgheight - 1\n",
    "            #Crop into patches of size MxN\n",
    "            tiles = image_copy[y:y+M, x:x+N]\n",
    "            #Save each patch into file directory\n",
    "            cv2.imwrite('saved_patches/'+'tile'+str(x)+'_'+str(y)+'.jpg', tiles)\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "        elif y1 >= imgheight: # when patch height exceeds the image height\n",
    "            y1 = imgheight - 1\n",
    "            #Crop into patches of size MxN\n",
    "            tiles = image_copy[y:y+M, x:x+N]\n",
    "            #Save each patch into file directory\n",
    "            cv2.imwrite('saved_patches/'+'tile'+str(x)+'_'+str(y)+'.jpg', tiles)\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "        elif x1 >= imgwidth: # when patch width exceeds the image width\n",
    "            x1 = imgwidth - 1\n",
    "            #Crop into patches of size MxN\n",
    "            tiles = image_copy[y:y+M, x:x+N]\n",
    "            #Save each patch into file directory\n",
    "            cv2.imwrite('saved_patches/'+'tile'+str(x)+'_'+str(y)+'.jpg', tiles)\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "        else:\n",
    "            #Crop into patches of size MxN\n",
    "            tiles = image_copy[y:y+M, x:x+N]\n",
    "            #Save each patch into file directory\n",
    "            cv2.imwrite('saved_patches/'+'tile'+str(x)+'_'+str(y)+'.jpg', tiles)\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Patched Image\",img)\n",
    "cv2.imwrite(\"patched.jpg\",img)\n",
    "  \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotação de imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.70710678   0.70710678 -91.16208435]\n",
      " [ -0.70710678   0.70710678 461.91525958]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./test.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "center = (width/2, height/2)\n",
    "\n",
    "rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=45, scale=1)\n",
    "\n",
    "print(rotate_matrix)\n",
    "\n",
    "rotated_image = cv2.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "\n",
    "cv2.imshow('Original image', image)\n",
    "cv2.imshow('Rotated image', rotated_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite('rotate_image.jpg', rotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaços de cor\n",
    "\n",
    "O espaço de cor RGB possui as seguintes propriedades:\n",
    "* É um espaço de cor aditivo onde cores são obtidas com a combinação linear de valores de Vermelho, Azul e Verde\n",
    "* Os três canais são correlacionados pela quantidade de luz na superfície\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubos = cv2.imread('two-cubes.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
