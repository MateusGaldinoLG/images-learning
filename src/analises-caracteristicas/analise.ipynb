{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de características em imagens \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado é o CIFAR-10. O CIFAR-10 é um dataset desenvolvido pelo instituto canadense de pesquisa avançada (CIFAR) a partir de 10 classes de imagens, cada uma com 6000 imagens de 32x32 pixels.\n",
    "\n",
    "Ao baixar os dados utilizando os comandos de ```rotina.sh```, eles vem em batches, que são arquivos binários formados por arrays com os valores RGB de cada imagem. Os arquivos data_batch possuem os dados que serão usados para o treino, sendo cada um formado de 10000 arrays de 3072 linhas, com 1024 entradas de valores de Vermelho (R), Azul (B) e Verde (G) formando os pixels da imagem 32x32.\n",
    "\n",
    "Vamos transformar esses arrays de 3072 linhas em arrays de 1024 linhas de três entradas cada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_1\n",
      "data_batch_2\n",
      "data_batch_3\n",
      "data_batch_4\n",
      "data_batch_5\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def load_batch():\n",
    "    path = 'cifar-10-batches-py/'\n",
    "\n",
    "    imagens = []\n",
    "    labels = np.zeros(50000)\n",
    "    count = 0\n",
    "\n",
    "    for i in range(1, 6, 1):\n",
    "        file = f'data_batch_{i}'\n",
    "        print(file)\n",
    "        f = open(path+file, 'rb')\n",
    "        df = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        images = df['data']\n",
    "        #images = np.reshape(images, (10000, 3, 32, 32))\n",
    "        label = df['labels']\n",
    "        imagearray = np.array(images)   #   (10000, 3072)\n",
    "        labelarray = np.array(label)   #   (10000,)\n",
    "\n",
    "        for j in range(0, len(imagearray), 10):\n",
    "            image = np.transpose(np.reshape(imagearray[j], (3, 32, 32)), (1, 2, 0))\n",
    "            imagens.append(image)\n",
    "            labels[count+j] = labelarray[j]\n",
    "\n",
    "        count = count + 10000\n",
    "\n",
    "    return imagens, labelarray\n",
    "\n",
    "def load_test_batch():\n",
    "    path = 'cifar-10-batches-py/'\n",
    "    file = 'test_batch'\n",
    "\n",
    "    f = open(path+file, 'rb')\n",
    "    dict = pickle.load(f, encoding='latin1')\n",
    "    images = dict['data']\n",
    "    #images = np.reshape(images, (10000, 3, 32, 32))\n",
    "    labels = dict['labels']\n",
    "    imagearray = np.array(images)   #   (10000, 3072)\n",
    "    labelarray = np.array(labels)   #   (10000,)\n",
    "\n",
    "    imagens = []\n",
    "    label = []\n",
    "\n",
    "    for j in range(0, len(imagearray), 10):\n",
    "        image = np.transpose(np.reshape(imagearray[j], (3, 32, 32)), (1, 2, 0))\n",
    "        imagens.append([image])\n",
    "        label.append(labelarray[j])\n",
    "    \n",
    "    return imagearray, labelarray\n",
    "\n",
    "imagearray, labelarray = load_batch()\n",
    "test_image, test_label = load_test_batch()\n",
    "print(len(imagearray))\n",
    "print(len(test_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de características\n",
    "\n",
    "### Características de cor\n",
    "\n",
    "Como as imagens estão usando o espaço de cor BGR, vamos utilizar características de cor relacionadas ao espaço RGB, como por exemplo:\n",
    "\n",
    "* Momentos de Cor (CM): Utiliza cálculos de média, desvio padrão e assimetria da imagem, cálculados para cada cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9636/244653972.py:26: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew_azul = skew(azul)\n",
      "/tmp/ipykernel_9636/244653972.py:27: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew_verde = skew(verde)\n",
      "/tmp/ipykernel_9636/244653972.py:28: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew_vermelho = skew(vermelho)\n"
     ]
    }
   ],
   "source": [
    "def CM(imagens):\n",
    "    medias = []\n",
    "    stds= []\n",
    "    skews = []\n",
    "    for imagem in imagens:\n",
    "\n",
    "        azul = imagem[:, :, 0]\n",
    "        verde = imagem[:, :, 1]\n",
    "        vermelho = imagem[:, :, 2]\n",
    "        \n",
    "        # Calculo de médias\n",
    "        media_azul = np.mean(azul)\n",
    "        media_verde = np.mean(verde)\n",
    "        media_vermelho = np.mean(vermelho)\n",
    "        media = [media_azul, media_verde, media_vermelho]\n",
    "        medias.append(media)\n",
    "\n",
    "        # Calculo de desvio padrão\n",
    "        std_azul = np.std(azul)\n",
    "        std_verde = np.std(verde)\n",
    "        std_vermelho = np.std(vermelho)\n",
    "        std = [std_azul, std_verde, std_vermelho]\n",
    "        stds.append(std)\n",
    "\n",
    "        # Calculo da assimetria\n",
    "        skew_azul = skew(azul)\n",
    "        skew_verde = skew(verde)\n",
    "        skew_vermelho = skew(vermelho)\n",
    "        assim = [skew_azul, skew_verde, skew_vermelho]\n",
    "        # print(assim)\n",
    "        skews.append(assim)\n",
    "        \n",
    "\n",
    "CM(imagearray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características de textura\n",
    "\n",
    "Como extrator de características de textura, vamos utilizar o Filtro de Gabor. O filtro de gabor faz a amostragem do domínio da frequência inteiro de uma imagem pelas características de frequência central e parâmetros de orientação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter(imagens):\n",
    "    sigma = 8.0\n",
    "    theta = np.pi / 4\n",
    "    lambd = 10.0\n",
    "    gamma = 0.5\n",
    "    psi = 0\n",
    "    gabor_kernel = cv2.getGaborKernel((21, 21), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
    "\n",
    "    # for img in imagens:\n",
    "    filtered_imgs = []\n",
    "    for img in imagens:\n",
    "        filtered_imgs.append(\n",
    "            cv2.filter2D(\n",
    "                cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                cv2.CV_8UC3,\n",
    "                gabor_kernel\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return filtered_imgs\n",
    "\n",
    "filtered_imgs = gabor_filter(imagearray)\n",
    "\n",
    "img = cv2.cvtColor(np.concatenate(imagearray[0:5], axis=1), cv2.COLOR_BGR2GRAY)\n",
    "filtered_img = np.concatenate(filtered_imgs[0:5], axis = 1)\n",
    "\n",
    "cv2.imshow(\"gabor\", np.concatenate((img, filtered_img), axis=0))\n",
    "# cv2.imshow('imagem nao alterada', img)\n",
    "# cv2.imshow('teste', filtered_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise utilizando Machine Learning\n",
    "\n",
    "O algoritmo de machine learning utilizado para classificar as imagens será o Support Vector Machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "https://gvpress.com/journals/IJMUE/vol8_no4/39.pdf\n",
    "Kumar, G., & Bhatia, P. K. (2014). A Detailed Review of Feature Extraction in Image Processing Systems. 2014 Fourth International Conference on Advanced Computing & Communication Technologies. doi:10.1109/acct.2014.74\n",
    "Wang, X., Ding, X., & Liu, C. (2005). Gabor filters-based feature extraction for character recognition. Pattern Recognition, 38(3), 369–379. doi:10.1016/j.patcog.2004.08.00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
